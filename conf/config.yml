DATA_SPLITS:
  train_test_ratio: 0.95
  train_val_ratio: 0.90

RANDOM_SEED: null

DATASET: CustomDfImageFolder

DATA_LOADER:
  batch_size: 16
  num_workers: 1
  pin_memory: True

DATA_TRANSFORM_AND_AUGMENTATION:
  train:
    Resize: 
        size: [336, 336]
#    RandAugment: 
#        num_ops: 3
#        magnitude: 10
    TrivialAugmentWide:
        num_magnitude_bins: 31
    ToTensor: {}
    Normalize: {}
  val:
    Resize: 
        size: [336, 336]
    ToTensor: {}
    Normalize: {}
  test:
    Resize: 
        size: [336, 336]
    ToTensor: {}
    Normalize: {}

MODEL_PARAMS:
  hidden_units: 32
  epochs: 500
  loss_func: CrossEntropyLoss
  metrics : [accuracy, precision, recall, f1]
  torchmetrics:
    ConfusionMatrix:
      task: multiclass
      num_classes: 4
  activation_func: LeakyReLU
  optimizer: 
    Adam:
      lr: 0.001
  lr_scheduler:
    ReduceLROnPlateau:
      mode: min
      factor: 0.25
      patience: 1
  early_stopping:
    patience: 10
    delta: 0
    saving_option: model
    verbose: True





